# -*- coding: utf-8 -*-
"""Gaussian Process Regression Template

Automatically generated by Colaboratory.

# 1. Load a dataset
"""

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Load your dataset here
# Example: data = pd.read_csv('your_dataset.csv')

# Display the first 5 rows of the dataset
data.head()

"""# 2. Clean the data"""

# Display missing values
data.isnull().sum()

# Drop missing values and unnecessary columns
numerical_data = data.drop(['col1', 'col2', 'col3'], axis=1)  # Replace 'col1', 'col2', 'col3' with actual column names
data_no_mv = numerical_data.dropna(axis=0)

data_no_mv.isnull().sum()

data_no_mv.describe(include='all')

data_no_mv.info()

# Display pairplots for selected columns
sns.pairplot(data_no_mv)

data_no_mv.corr()

"""#3. Plot correlation matrix"""

# Drop unnecessary columns for correlation matrix
df_new = data.drop(['col1', 'col2', 'col3'], axis=1)  # Replace 'col1', 'col2', 'col3' with actual column names

# Compute the correlation matrix
correlation_matrix = df_new.corr()

# Create the correlation matrix plot
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

import seaborn as sns

sns.heatmap(df_new.corr());

sns.pairplot(df_new);

"""# 4. Run the regression"""

# Define target variable (y) and features (X)
y = data_no_mv['target_column']  # Replace 'target_column' with the actual target column name
X = data_no_mv.drop('target_column', axis=1)  # Replace 'target_column' with the actual target column name

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Import GaussianProcessRegressor
from sklearn.gaussian_process import GaussianProcessRegressor

# Fitting the Gaussian Process Regression to the Training set
regressor = GaussianProcessRegressor()
regressor.fit(X, y)

# Predicting the Test set results
y_pred = regressor.predict(X)

# Display string values in X (if any)
string_values = [val for val in X if isinstance(val, str)]
print("String values in X:", string_values)

"""# 5. Display the evaluation metrics"""

import seaborn as sns

# Gaussian Process Regression
regressor = GaussianProcessRegressor()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
regressor.fit(X_train, y_train)
y_pred, _ = regressor.predict(X_test, return_std=True)

# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
explained_variance = explained_variance_score(y_test, y_pred)

# Displaying evaluation metric results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (R2) Score: {r2}')
print(f'Explained Variance Score: {explained_variance}')
print()

# Visualize the results (scatter plot)
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
sns.lineplot(x=y_test, y=y_test)
plt.xlabel('Actual count', fontsize=14)
plt.ylabel('Predicted count', fontsize=14)
plt.title('Actual vs Predicted count (test set)', fontsize=17)
plt.show()

"""# 6. Default parameter"""

from sklearn.gaussian_process import GaussianProcessRegressor

# Create instances of the regression models and feature transformation
gaussian_process = GaussianProcessRegressor()

# Get default hyperparameters
default_gaussian_process_params = gaussian_process.get_params()

# Print the default hyperparameters
print("\nDefault Hyperparameters for Gaussian Process Regression:")
print(default_gaussian_process_params)

"""#7. Feature selection ANOVA and Recursive Feature Elimination (RFE)

## ANOVA
"""

# Import necessary libraries
import statsmodels.api as sm
from statsmodels.formula.api import ols

data_no_mv.head()

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'data_no_mv' is your DataFrame
plt.figure(figsize=(12, 8))

# Line plot for feature1
sns.lineplot(x='feature1', y='target_column', data=data_no_mv, label='feature1')  # Replace 'feature1' with actual column name

# Line plot for feature2
sns.lineplot(x='feature2', y='target_column', data=data_no_mv, label='feature2')  # Replace 'feature2' with actual column name

# Line plot for feature3
sns.lineplot(x='feature3', y='target_column', data=data_no_mv, label='feature3')  # Replace 'feature3' with actual column name

# Line plot for feature4
sns.lineplot(x='feature4', y='target_column', data=data_no_mv, label='feature4')  # Replace 'feature4' with actual column name

# Line plot for feature5
sns.lineplot(x='feature5', y='target_column', data=data_no_mv, label='feature5')  # Replace 'feature5' with actual column name

plt.title('Line Plots of target_column based on Categorical Variables')
plt.xlabel('Categories')
plt.ylabel('target_column Values')
plt.legend(title='Categorical Variable')
plt.show()

model = ols('target_column ~ feature1 + feature2 + feature3 + feature4 + feature5', data=data).fit()
anova = sm.stats.anova_lm(model, typ=2)
anova

# Run the regression with selected features

data_new = data_no_mv[['target_column', 'feature1', 'feature2', 'feature4']]  # Replace feature names accordingly

y_new = data_new['target_column']
X_new = data_new.drop('target_column', axis=1)

# Gaussian Process Regression
regressor = GaussianProcessRegressor()

X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)

# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
explained_variance = explained_variance_score(y_test, y_pred)

# Displaying evaluation metric results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (R2) Score: {r2}')
print(f'Explained Variance Score: {explained_variance}')
print()

# Visualize the results (scatter plot)
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
sns.lineplot(x=y_test, y=y_test)
plt.xlabel('Actual count', fontsize=14)
plt.ylabel('Predicted count', fontsize=14)
plt.title('Actual vs Predicted count (test set)', fontsize=17)
plt.show()

"""## Recursive Feature Elimination (RFE)"""

# Import necessary libraries
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Create the RFE model with Linear Regression
rfe = RFE(estimator=LinearRegression(), n_features_to_select=3)
rfe.fit(X, y)

# Print selected features and their rankings
for i, col in zip(range(len(X.columns)), X.columns):
    print(f"{col} selected={rfe.support_[i]} rank={rfe.ranking_[i]}")

# Plotting the bar graph for feature rankings
plt.figure(figsize=(10, 6))
plt.bar(range(len(rfe.ranking_)), rfe.ranking_)
plt.xticks(range(len(X.columns)), X.columns, rotation=45, ha='right')
plt.xlabel('Features')
plt.ylabel('Ranking')
plt.title('Feature Rankings from RFE')
plt.show()

# Run the regression with selected features

data_new = data_no_mv[['target_column', 'feature1', 'feature3', 'feature5']]  # Replace feature names accordingly

y_new = data_new['target_column']
X_new = data_new.drop('target_column', axis=1)

# Gaussian Process Regression
regressor = GaussianProcessRegressor()

X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)

# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
explained_variance = explained_variance_score(y_test, y_pred)

# Displaying evaluation metric results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (R2) Score: {r2}')
print(f'Explained Variance Score: {explained_variance}')
print()

# Visualize the results (scatter plot)
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
sns.lineplot(x=y_test, y=y_test)
plt.xlabel('Actual count', fontsize=14)
plt.ylabel('Predicted count', fontsize=14)
plt.title('Actual vs Predicted count (test set)', fontsize=17)
plt.show()
