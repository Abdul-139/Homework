# -*- coding: utf-8 -*-
"""Random Forest Regression

Automatically generated by Colaboratory.

# 1. Load a dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
import statsmodels.api as sm

# Load your dataset here
# Example: data = pd.read_csv('your_dataset.csv')

# Display the first 10 rows of the dataset
data.head(10)

"""# 2. Clean the data"""

data.info()

"""First, check if any data is missing"""

data.isnull().sum()

numerical_data = data.drop(data.columns[[0, 1]], axis=1)

# Descriptive statistics are very useful for the initial exploration of the variables
# By default, only descriptives for the numerical variables are shown
# To include the categorical ones, you should specify this with an argument
numerical_data.describe(include='all')

# Let's simply drop all missing values
# This is not always recommended, however, when we remove less than 5% of the data, it is okay

df = numerical_data.dropna(axis=0)

# Let's check the descriptives without the missing values
df.describe(include='all')

"""#3. Plot correlation matrix"""

df_new = df.drop(df.columns[[2, 3, 4]], axis=1)

# Compute the correlation matrix
correlation_matrix = df_new.corr()

# Create the correlation matrix plot
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

import seaborn as sns

sns.heatmap(df_new.corr());

sns.pairplot(df_new);

"""# 4. Run the regression

### Defining the variables and splitting the data
"""

rand_state = 1000

y = df[df.columns[-1]]
X = df.iloc[:, :-1]  # be careful inplace=False

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rand_state)

"""## Random Forest Regression with Sklearn"""

from sklearn.ensemble import RandomForestRegressor

# Fitting RF regression to the Training set
RF_regression = RandomForestRegressor(random_state=rand_state)
RF_regression.fit(X_train, y_train)

# Predicting the Test set results
y_hat = RF_regression.predict(X_test)

predictions = pd.DataFrame({'y_test': y_test, 'y_hat': y_hat})
predictions.head()

"""# 5. Display the evaluation metrics

---
## Evaluating the model performance on the test data
"""

# Define the models
model = [
    ('Random Forest', RandomForestRegressor())
]
sns.scatterplot(x=y_test, y=y_hat, alpha=0.6)
sns.lineplot(x=y_test, y=y_test)

# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_hat)
mae = mean_absolute_error(y_test, y_hat)
r2 = r2_score(y_test, y_hat)
explained_variance = explained_variance_score(y_test, y_hat)

# Displaying evaluation metric results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (R2) Score: {r2}')
print(f'Explained Variance Score: {explained_variance}')
print()

plt.xlabel('Actual count', fontsize=14)
plt.ylabel('Predicted count', fontsize=14)
plt.title('Actual vs Predicted count (test set)', fontsize=17)
plt.show()

"""---
---

#6. Tuning hyperparameters:
### Gridsearch
"""

my_param_grid = {'n_estimators': [10, 100, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [5, 10, 20]}

from sklearn.model_selection import GridSearchCV

grid = GridSearchCV(estimator=RandomForestRegressor(random_state=rand_state), param_grid=my_param_grid, refit=True,
                    verbose=2, cv=5)
# verbose just means the text output describing the process. (the greater the number the more detail you will get).

# May take a while!
grid.fit(X_train, y_train)

grid.best_params_

grid.best_estimator_

y_hat_optimized = grid.predict(X_test)

predictions['y_hat_optimized'] = y_hat_optimized
predictions.head()

# Define the models
models = [
    ('Random Forest', RandomForestRegressor())
]

sns.scatterplot(x=y_test, y=y_hat_optimized, alpha=0.6)
sns.lineplot(x=y_test, y=y_test)

# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_hat)
mae = mean_absolute_error(y_test, y_hat)
r2 = r2_score(y_test, y_hat)
explained_variance = explained_variance_score(y_test, y_hat)

# Displaying evaluation metric results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (R2) Score: {r2}')
print(f'Explained Variance Score: {explained_variance}')
print()

plt.xlabel('Actual count', fontsize=14)
plt.ylabel('Predicted count', fontsize=14)
plt.title('Actual vs Predicted count (test set)', fontsize=17)
plt.show()

#sns.scatterplot(x=y_test, y=y_hat_optimized, alpha=0.6)
#sns.lineplot(x=y_test, y=y_test)

#plt.xlabel('Actual price', fontsize=14)
#plt.ylabel('Predicted price', fontsize=14)
#plt.title('Actual vs Optimized Predicted price (test set)', fontsize=17)
#plt.show()

np.round(grid.score(X_test, y_test), 4)

MSE_test_opt = round(np.mean(np.square(y_test - y_hat_optimized)), 2)
MSE_test_opt

MSE_test_opt = round(np.mean(np.square(y_test - y_hat_optimized)), 2)
RMSE_test_opt = round(np.sqrt(MSE_test_opt), 2)
RMSE_test_opt

"""#### Cross validation
We will use Cross validation to estimate performance metrics in the test set.
"""

from sklearn.model_selection import cross_val_score

R2 = cross_val_score(estimator=RandomForestRegressor(max_depth=20, max_features='sqrt', n_estimators=500), X=X_train,
                     y=y_train, cv=5, scoring="r2")

R2_CV = round(np.mean(R2), 4)
R2_CV

"""---

#7. Feature selection

---

### Feature Importance
"""

features = list(X_train.columns)
features

RF_Regressor = RandomForestRegressor(n_estimators=500, max_features='sqrt', max_depth=20, random_state=rand_state)
RF_Regressor.fit(X_train, y_train)

importance = RF_Regressor.feature_importances_
importance

FIM = pd.DataFrame({'Features': X_train.columns, 'Feature_importance': importance})
FIM = FIM.sort_values(by=['Feature_importance'])
FIM

plt.figure(figsize=(10, 6))
plt.title('Feature Importance')
sns.barplot(y='Features', x='Feature_importance', data=FIM)
plt.show()

"""## Random Forest Regression with Sklearn - NEW"""

df.shape

df_FI = df.drop(df.columns[[4, 5, 6, 7, 8]], axis=1)

df_FI

y_new = df_FI[df_FI.columns[-1]]
X_new = df_FI.iloc[:, :-1]  # be careful inplace=False

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.3, random_state=rand_state)

from sklearn.ensemble import RandomForestRegressor

# Fitting RF regression to the Training set
RF_regression = RandomForestRegressor(random_state=rand_state)
RF_regression.fit(X_train, y_train)

# Predicting the Test set results
y_hat = RF_regression.predict(X_test)

predictions = pd.DataFrame({'y_test': y_test, 'y_hat': y_hat})
predictions.head()

import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Define the models
model = [
    ('Random Forest', RandomForestRegressor())
]
sns.scatterplot(x=y_test, y=y_hat, alpha=0.6)
sns.lineplot(x=y_test, y=y_test)

# Calculating evaluation metrics
mse = mean_squared_error(y_test, y_hat)
mae = mean_absolute_error(y_test, y_hat)
r2 = r2_score(y_test, y_hat)
explained_variance = explained_variance_score(y_test, y_hat)

# Displaying evaluation metric results
print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'R-squared (R2) Score: {r2}')
print(f'Explained Variance Score: {explained_variance}')
print()

plt.xlabel('Actual count', fontsize=14)
plt.ylabel('Predicted count', fontsize=14)
plt.title('Actual vs Predicted count (test set)', fontsize=17)
plt.show()

"""---
---

## Does a more important feature mean more significant?
"""

import statsmodels.api as sm

# With statsmodels, we need to manually add a constant to our dataset!
X_test_wc = sm.add_constant(X_test)
X_train_wc = sm.add_constant(X_train)

# Fit the model
model = sm.OLS(y_train, X_train_wc)
statsmodels_reg = model.fit()

statsmodels_reg.summary()

"""---

###  Additional links:

1. Decision Trees with sklearn: https://scikit-learn.org/stable/modules/tree.html
2. Ensemble learning with sklearn: https://scikit-learn.org/stable/modules/ensemble.html
3. graphviz: this is used for Tree visualization: http://graphviz.org/
4. Out of Bag errors for random forest: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html#sphx-glr-auto-examples-ensemble-plot-ensemble-oob-py
